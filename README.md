# DDPG_CNN_Pendulum
I used the CNN + DDPG realizing inverted pendulum control
python3.5
tensorflow + GPU
gym环境
***************************** 写在前面 *****************************************
这个只是一个最简单的测试代码，主要是验证算法是否可行。

运行效果不好，看了TRPO作者的论文（https://arxiv.org/abs/1502.05477）
Ataria游戏使用了卷积神经网络来进行实现，但是针对于gym下的机器人控制直接使用的是全连接网络，根本没有考虑使用卷积神经网络；再次查阅baselines（OpneAI旗下的git）其中使用PPO与DDPG在用于连续动作的时候调用网络的时候使用的是mlp，在用于离散动作（针对于Ataria游戏：breakout、pong等）时仅在PPO中调用了cnn网络，其他均使用的是mlp。


但是在离散动作，使用卷积神经网络时尽量选择DQN，我们使用DQN + CNN 可以实现想要的结果，转化为连续型时用DDPG以及PPO + CNN均没有训练出结果

############################  代码解释  ##################################

其中CNN_1与CNN_2是根据全连接进行改造的
CNN_1中是在第二个卷积层的输出中加入Actor网络的输出Policy
CNN_2中是在地一个全连接的输出中加入Actor网络的输出Policy

两个版本最后运行的结果都不太理想，卷积网路所使用的图像是使用pygame进行绘制的。

对于全连接网络来说，网络的输入有（角度的cos值，角度的sin值，角速度）
而卷积神经网络，我只使用了角度信息进行绘制，角速度信息没有使用到。

继续修改plot代码，进行训练。

添加了角速度的信息，以摆杆的支点为圆心画圆，当速度越大，半径越大，且具有方向信息，顺时针与逆时针使用颜色进行区分。


